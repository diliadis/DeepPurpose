{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dimitriosi_datasets/anaconda3/envs/DeepPurpose_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from DeepPurpose import utils, dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from DeepPurpose.utils import *\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from AutoEncoder import AutoEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_model_to_use = 'protein'\n",
    "drug_encoding = 'MPNN'\n",
    "target_encoding = 'CNN'\n",
    "\n",
    "wandb_project_name = 'DeepPurpose'\n",
    "wandb_project_entity = 'diliadis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Beginning to extract zip file...\n",
      "Default set to logspace (nM -> p) for easier regression\n",
      "Done!\n",
      "Processing the dataset...\n",
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 30056 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 68\n",
      "encoding protein...\n",
      "unique target sequence: 379\n",
      "splitting dataset...\n",
      "Done.\n",
      "Done! \n",
      "Splitting the dataset...\n",
      "Done! \n"
     ]
    }
   ],
   "source": [
    "X_drugs, X_targets, y = dataset.load_process_DAVIS(path = './data', binary = False, convert_to_log = True, threshold = 30) # http://staff.cs.utu.fi/~aatapa/data/DrugTarget/\n",
    "drug_encoding, target_encoding = drug_encoding, target_encoding\n",
    "print('Processing the dataset...')\n",
    "train, _, _ = utils.data_process(X_drugs, X_targets, y, \n",
    "                            drug_encoding, target_encoding, \n",
    "                            split_method='random',frac=[0.7,0.1,0.2],\n",
    "                            random_seed = 1)\n",
    "print('Done! ')\n",
    "\n",
    "# get the feature representations of the unique drugs or proteins\n",
    "data = train.drop_duplicates('SMILES' if branch_model_to_use=='drug' else 'Target Sequence', ignore_index=True)['SMILES' if branch_model_to_use=='drug' else 'target_encoding']\n",
    "\n",
    "frac = {'train': 0.8, 'val': 0.1, 'test': 0.2}\n",
    "print('Splitting the dataset...')\n",
    "# split to train, val, test\n",
    "train, test = train_test_split(data, test_size=frac['test'], random_state=42)\n",
    "train, val = train_test_split(train, test_size=frac['val']/(1-frac['test']), random_state=42)\n",
    "print('Done! ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'wandb_project_name': 'Protein_autoencoder',\n",
    "    'wandb_project_entity': 'diliadis',\n",
    "    \n",
    "    'drug_encoding': 'MPNN',\n",
    "    'target_encoding': 'CNN',\n",
    "    \n",
    "    'cuda_id': '7',\n",
    "    'num_workers': 2,\n",
    "    \n",
    "    # 'experiment_name': 'autoencoder_'+branch_model_to_use+'_',\n",
    "    'experiment_name': None,\n",
    "    'result_folder': './results/',\n",
    "    \n",
    "    'decay': 0,\n",
    "    'LR': 0.001,\n",
    "    \n",
    "    'batch_size': 32,\n",
    "    'train_epoch': 100,\n",
    "    'test_every_X_epoch': 5,\n",
    "    \n",
    "    'cnn_filters': [32, ],\n",
    "    'cnn_kernels': [3, ],\n",
    "    \n",
    "    'use_early_stopping': True,\n",
    "    'patience': 5,\n",
    "    'delta': 0.0005,\n",
    "    'metric_to_optimize_early_stopping': 'loss',\n",
    "    'metric_to_optimize_best_epoch_selection': 'loss',\n",
    "    \n",
    "    'save_model': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following device: cuda:7\n",
      "Early stopping detected metric: loss\n"
     ]
    }
   ],
   "source": [
    "# inialize the model\n",
    "model = AutoEncoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder_model(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv1d(26, 32, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose1d(32, 26, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiliadis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/dimitriosi_datasets/dot_vs_mlp/auto_encoders/wandb/run-20221115_110414-oo02rip9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diliadis/Protein_autoencoder/runs/oo02rip9\" target=\"_blank\">smooth-firefly-14</a></strong> to <a href=\"https://wandb.ai/diliadis/Protein_autoencoder\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train batches: 9\n",
      "Num validation batches: 2\n",
      "Num test batches: 3\n",
      "Epoch 0 train_loss: 0.04039204388869935\n",
      "      0 val_loss: 0.038373717370378355\n",
      "Epoch 1 train_loss: 0.03741528709588252\n",
      "      1 val_loss: 0.036288342483711974\n",
      "Epoch 2 train_loss: 0.03578236058605298\n",
      "      2 val_loss: 0.03446376088263946\n",
      "Epoch 3 train_loss: 0.03416070617394238\n",
      "      3 val_loss: 0.033065809674102976\n",
      "Epoch 4 train_loss: 0.03258077238052728\n",
      "      4 val_loss: 0.031266409486905324\n",
      "Epoch 5 train_loss: 0.03102293299526201\n",
      "      5 val_loss: 0.030617624996152233\n",
      "Epoch 6 train_loss: 0.029635949803504844\n",
      "      6 val_loss: 0.027766013696475488\n",
      "Epoch 7 train_loss: 0.027712003904561706\n",
      "      7 val_loss: 0.02480164865093865\n",
      "Epoch 8 train_loss: 0.026404912173950114\n",
      "      8 val_loss: 0.02619596024168356\n",
      "-----------------------------EarlyStopping counter: 1 out of 5---------------------- best epoch currently 7\n",
      "Epoch 9 train_loss: 0.025091222366615033\n",
      "      9 val_loss: 0.02394995368610684\n",
      "Epoch 10 train_loss: 0.024262655268215014\n",
      "      10 val_loss: 0.02321642274325446\n",
      "Epoch 11 train_loss: 0.023454851764971377\n",
      "      11 val_loss: 0.02235507982477919\n",
      "Epoch 12 train_loss: 0.022945692501125603\n",
      "      12 val_loss: 0.021490200584028868\n",
      "Epoch 13 train_loss: 0.022676209179689762\n",
      "      13 val_loss: 0.019959665335446394\n",
      "Epoch 14 train_loss: 0.02237367748576724\n",
      "      14 val_loss: 0.02257612726570505\n",
      "-----------------------------EarlyStopping counter: 1 out of 5---------------------- best epoch currently 13\n",
      "Epoch 15 train_loss: 0.022123682279167913\n",
      "      15 val_loss: 0.022422503319277164\n",
      "-----------------------------EarlyStopping counter: 2 out of 5---------------------- best epoch currently 13\n",
      "Epoch 16 train_loss: 0.021734073399067057\n",
      "      16 val_loss: 0.021992417825720208\n",
      "-----------------------------EarlyStopping counter: 3 out of 5---------------------- best epoch currently 13\n",
      "Epoch 17 train_loss: 0.02178232851223572\n",
      "      17 val_loss: 0.021380339656843057\n",
      "-----------------------------EarlyStopping counter: 4 out of 5---------------------- best epoch currently 13\n",
      "Epoch 18 train_loss: 0.021658489877474246\n",
      "      18 val_loss: 0.021429685086714296\n",
      "-----------------------------EarlyStopping counter: 5 out of 5---------------------- best epoch currently 13\n",
      "Early stopping criterion met. Training stopped!!!\n",
      "TEST_loss: 0.02169093797719443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▅▅▄▃▃▃▂▂▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.01996</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>test_loss</td><td>0.02169</td></tr><tr><td>train_loss</td><td>0.02166</td></tr><tr><td>val_loss</td><td>0.02143</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smooth-firefly-14</strong>: <a href=\"https://wandb.ai/diliadis/Protein_autoencoder/runs/oo02rip9\" target=\"_blank\">https://wandb.ai/diliadis/Protein_autoencoder/runs/oo02rip9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221115_110414-oo02rip9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/15_11_2022__09_56_19/config.pkl\", \"rb\") as file_to_read:\n",
    "    config = pickle.load(file_to_read)\n",
    "    \n",
    "# inialize the model\n",
    "model = AutoEncoder(config)\n",
    "\n",
    "model.load_pretrained(\"results/15_11_2022__09_56_19/model.pt\", model.device)\n",
    "\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DeepPurpose_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25394f763b65794906a1520a5e350de27236fec0e3f27326c170a0c4ecd2d822"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
